---
layout: archive
title: "Publications"
permalink: /research/
author_profile: true
redirect_from:
---

{% include base_path %}

<h2 style="font-size: 18px;">
  <a href="https://www.sciencedirect.com/science/article/pii/S0899825624001428?via%3Dihub">
    Ridge Distributions and Information Design in Simultaneous All-Pay Auction Contests
  </a>
  (with Zhonghong Kuang and Jie Zheng). <i>Games and Economic Behavior (2024).</i>
</h2>


<details>
  <summary>Abstract</summary>
  <p style="font-size: smaller; margin-left: 40px;">
    <i>
      Two informed contestants compete in a contest, and the organizer ex-ante designs a public anonymous disclosure policy to maximize contestants' total effort. We fully characterize ridge distributions, under which the organizer achieves the first best outcome in equilibrium: the allocation is efficient, and the entire surplus goes to the organizer. When the prior is more positively correlated than ridge distributions, the first-best outcome is achievable by the signal that solely generates ridge distributions as posteriors.
    </i>
  </p>
</details>

<p></p><p></p>

<h1>Working Papers</h1>

<h2 style="font-size: 18px;">
  <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5279403">
    Algorithmic Collusion of Pricing and Advertising on E-commerce Platforms
  </a>
  [<a href="https://arxiv.org/abs/2406.00176">arXiv</a>]
   <i>Major Revision at Marketing Science</i>
</h2>
with <a href="https://ron-berman.com">Ron Berman</a>.


<i>Finalist, 2025 ASA Marketing Section Doctoral Dissertation Research Award</i>
<details>
  <summary>Abstract</summary>
  <p style="font-size: smaller; margin-left: 40px;">
    <i>
    Online sellers have been adopting AI learning algorithms to automatically make product pricing and advertising decisions on e-commerce platforms. When sellers compete using such algorithms, one concern is that of tacit collusionâ€”the algorithms learn to coordinate on higher than competitive prices which increase sellers' profits, but hurt consumers. This concern, however, was raised primarily when sellers use algorithms to decide on prices. We empirically investigate whether these concerns are valid when sellers make pricing and advertising decisions together, i.e., two-dimensional decisions. Our empirical strategy is to analyze competition with multi-agent reinforcement learning, which we calibrate to a large-scale dataset collected from Amazon.com products.
Our first contribution is to find conditions under which learning algorithms can facilitate win-win-win outcomes that are beneficial for consumers, sellers, and even the platform, when consumers have high search costs. In these cases the algorithms learn to coordinate on prices that are lower than competitive prices. The intuition is that the algorithms learn to coordinate on lower advertising bids, which lower advertising costs, leading to lower prices for consumers and enlarging the demand on the platform.
Our second contribution is an analysis of a large-scale, high-frequency keyword-product dataset for more than 2 million products on Amazon.com. Our estimates of consumer search costs show a wide range of costs for different product keywords. Among these products, more than 50% show evidence that prices are lower when more sellers adopt algorithms to choose their prices and bids. In these product markets, consumers benefit from tacit collusion facilitated by algorithms.
We also provide a proof that our results do not depend on the specific reinforcement-learning algorithm that we analyzed. They would generalize to any learning algorithm that uses price and advertising bid exploration.
Finally, we analyze the platform's strategic response through adjusting the ad auction reserve price or the sales commission rate. We find that reserve price adjustments will not increase profits for the platform, but commission adjustments will, while maintaining the beneficial outcomes for both sellers and consumers.
Our analyses help alleviate some worries about the potentially harmful effects of competing learning algorithms, and can help sellers, platforms and policymakers to decide on whether to adopt or regulate such algorithms.
    </i>
  </p>
</details>


<h2 style="font-size: 18px;">
  <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5992774">
    The Impact of LLMs on Online News Consumption and Production
  </a>
   <i>Under Review</i>
</h2>
with <a href="https://ron-berman.com">Ron Berman</a>.

<details>
  <summary>Abstract</summary>
  <p style="font-size: smaller; margin-left: 40px;">
    <i>
      Large language models (LLMs) change how consumers acquire information online; their bots also crawl news publishers' websites for training data and to answer consumer queries; and they provide tools that can lower the cost of content creation. These changes lead to predictions of adverse impact on news publishers in the form of lowered consumer demand, reduced demand for newsroom employees, and an increase in news "slop." Consequently, some publishers strategically responded by blocking LLM access to their websites using the robots.txt file standard. Using high-frequency granular data, we document four effects related to the predicted shifts in news publishing following the introduction of generative AI (GenAI). First, we find a moderate decline in traffic to news publishers occurring after August 2024. Second, using a difference-in-differences approach, we find that blocking GenAI bots can be associated with a reduction of total website traffic to large publishers compared to not blocking. Third, on the hiring side, we do not find evidence that LLMs are replacing editorial or content-production jobs yet. The share of new editorial and content-production job listings increases over time. Fourth, regarding content production, we find no evidence that large publishers increased text volume; instead, they significantly increased rich content and use more advertising and targeting technologies. Together, these findings provide early evidence of some unforeseen impacts of the introduction of LLMs on news production and consumption.
    </i>
  </p>
</details>

<h2 style="font-size: 18px;">
    Choosing the Winner: When and How to Correct for Selection Bias in Randomized Experiments
   <i>Under Review</i>
</h2>
with <a href="https://ron-berman.com">Ron Berman</a> and Walter W. Zhang.

<details>
  <summary>Abstract</summary>
  <p style="font-size: smaller; margin-left: 40px;">
    <i>
      Decision-makers often select the best-performing treatment in a randomized experiment for deployment. This practice leads to the winner's curse: the estimated performance of the selected treatment is biased upwards because selection might favor treatments that had higher outcomes by chance. We analyze this problem by distinguishing three distinct objectives. (1) Global winner's curse: the bias relative to the truly best treatment; (2) selected winner's curse: the bias relative to the deployed treatment's true mean; and (3) regret: the loss from selecting the wrong treatment compared to the truly best. We derive an identity linking these three quantities and show that methods optimal for estimating for one objective can underperform for others. We evaluate proposed solutions including sample splitting, cross-fitting, bootstrap bias correction, adaptive resampling, conditional inference, and a novel empirical likelihood approach. When we focus on decision-making scenarios that reflect realistic experimental decision making settings, our results provide practical guidance: cross-fitting excels when treatments have similar effects, bootstrap correction offers good MSE properties for moderate differences between treatments, and the simple plug-in estimator dominates when treatment effects are large or in the asymptotic regime. Our proposed adaptive empirical likelihood method provides valid confidence intervals without being sensitive to a tuning parameter like resampling methods.
    </i>
  </p>
</details>

<h2 style="font-size: 18px;">
  <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4301489">
    Strategic Design of Recommendation Algorithms
  </a>
</h2>
with <a href="https://ron-berman.com">Ron Berman</a> and <a href="https://carlsonschool.umn.edu/faculty/yi-zhu">Yi Zhu</a>.

<details>
  <summary>Abstract</summary>
  <p style="font-size: smaller; margin-left: 40px;">
    <i>
      We analyze recommendation algorithms that firms can engineer to strategically provide information to consumers about products with uncertain matches to their tastes. Monopolists who cannot alter prices can design recommendation algorithms to oversell, i.e., that recommend products even if they are not a perfect fit, instead of algorithmically recommending perfectly matching products. However, when prices are endogenous or when competition is rampant, firms opt to reduce their overselling efforts and instead choose to fully reveal the product's match (i.e., maximize recall and precision). As competition strengthens, the algorithms will shift to demarket their products, i.e., under-recommend highly fitting products, in order to soften price competition. When a platform designs a recommendation algorithm for products sold by third-party sellers, we find that demarketing might be a more prevalent strategy of the platform. Additionally, we find that platforms bound by fairness constraints may gain lower profits compared to letting sellers compete, while discriminatory designs do not necessarily result in preferential outcomes for a specific seller.
    </i>
  </p>
</details>


<p></p><p></p>

<h1>Work in Progress</h1>

<h2 style="font-size: 18px;">
    The Effectiveness of Digital Advertising Across Multiple Platforms
</h2>
with Kenneth C. Wilbur.

<h2 style="font-size: 18px;">
    Reinforcement Learning and Optimal Credit Allocation
</h2>
with Vitaly M. Bord, Agnes Kovacs, and Patrick Moran.

<h2 style="font-size: 18px;">
    A Transformer-Based Framework for Consumer Search Modeling
</h2>
with Zhenling Jiang.
